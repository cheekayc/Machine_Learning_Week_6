---
title: "CaRT Demonstration"
author: "JAS"
output: github_document
editor_options:
  chunk_output_type: console
---

```{r setup, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

library(tidyverse)
library(rpart) # construct CaRT
library(caret) # construct CaRT
library(rpart.plot) # makes cleaner looking tree plots
library(pROC) # generate ROC
```

# Demonstration of Classification and Regression Trees (CaRT)

This demonstration of classification and regression trees (CaRT) will utilize the 2019 County Health Rankings. The rankings provide data on a number of demographic, social and environmental health characteristics for counties in the United States. We will be using this dataset to address two research questions:

1. What are the predictors of life expectancy on a county-level?

2. Imagine a scenario where the maintainers of the CHR were concerned that the data on firearm fatalities would no longer be made public. This information has been used by a number of foundations to target population-based interventions at reducing gun violence. They are wondering if the counties with higher proportions of firearm fatalities would still be able to be identified, based on the other data within the CHR. That is, can the other data in the CHR be used to classify counties according to having higher or lower firearm_fatalities?

The first question will be addressed with a **regression tree**, while the second will be addressed with a **classification tree**.

***

### Load and check data

Variable names in the original dataset were not informative, so we need to append our own as column names. We also need to strip off the Id variable for easier processing. We're also going to look at some basic descriptives of the data to determine if it needs cleaning, imputation of missing data, etc.

```{r data_prep}
chr = read.csv("./Data/chr.csv")

#Stripping off ID Variable
chr = chr[,2:68]

#Assigning informative variable names
var.names = c("pre_death", "poorhealth", "poorphyshealth_days", "poormenthealth_days", "low_bwt", "ad_smoking", "ad_obesity", "foodenv_index", "phys_inactivity", "exer_access", "excess_drink", "alc_drivdeaths", "sti", "teen_birth", "uninsured", "primcareproviders", "dentists", "menthealthproviders", "prevhosp", "mammo_screen", "flu_vacc", "hsgrad", "somecollege", "unemployed", "child_poverty", "income_ineq", "sing_parent", "social_assoc", "violent_crime", "injury_deaths", "pm_air", "water_viol", "housing_prob", "driving_alone", "long_commute", "life_exp", "age_adj_premortality", "freq_physdistress", "freq_mentdistress", "diabetes", "hiv", "food_insecure", "ltd_access_healthyfood", "mvcrash_deaths", "insuff_sleep", "uninsured_adults", "uninsured_child", "other_pcp", "medhhinc", "freelunch_child", "res_seg_bw", "res_seg_nw", "firearm_fatalities", "homeownership", "hous_cost_burden", "population", "bw18", "gte65", "nonhisp_afam", "AmerInd_AlasNative", "Asian", "OPacIslander", "Hisp", "nonhisp_white", "nonprof_english", "female", "rural")

colnames(chr) = var.names

#Stripping off `premature mortality` and `premature death` as they are different metrics of mortality that are highly correlated with life expectancy (they are another measures of life expectancy) 
chr = chr %>% 
  select(-age_adj_premortality, -pre_death)

# The `complete.cases()` function will identify any rows that do not have complete cases (i.e. have missing data)
## This dataset have no missing values
miss.rows = chr[!complete.cases(chr), ] # find rows that is not complete cases

summary(chr)
#variables have very different distributions, but tree-based methods do not require scaling.

#Create the variable for Part 2, an indicator of having fire-arm fatalities above the median
chr$firearm.class = as.factor(ifelse(chr$firearm_fatalities > median(chr$firearm_fatalities), 1, 0))
summary(chr$firearm.class)
#Note that data are slightly unbalanced.
```

### Partition data into training and testing sets.

```{r datapart}
set.seed(123)

#To address Question 1 
training.data.q1 = 
  chr$life_exp %>% 
  createDataPartition(p = 0.7, list = F)

train.data.q1 = chr[training.data.q1, ]
test.data.q1 = chr[-training.data.q1, ]

#Remove firearm.class variable as its only used for Question 2 by base R method
train.data.q1$firearm.class = NULL
test.data.q1$firearm.class = NULL

#To address Question 2
training.data.q2 = 
  chr$firearm.class %>% 
  createDataPartition(p = 0.7, list = F)

train.data.q2 = chr[training.data.q2, ]
test.data.q2 = chr[-training.data.q2, ]

#Remove firearm fatalities variable as it was used to create our new outcome variable
train.data.q2$firearm_fatalities<-NULL
test.data.q2$firearm_fatalities<-NULL
```

## PART 1: REGRESSION TREES

We will create a number of regression trees to predict life expectancy. `Caret` calls to `rpart` (meaning `rpart` belongs to `Caret`), but doesn't have the same level of hyperparameter turning as `rpart`. In `caret`, you can only change the **complexity parameter** (**cp**). In addition, `caret` automatically performs pruning (whereas in `rpart` you, by default, can see the full tree.)

From within `caret`, you can still visualize the tree and get measures of variable importance. 

Variable Importance: "An overall measure of variable importance is the sum of the goodness of split measures for each split for which it was the primary variable."

```{r regtree}
# Check what `rpart` can do
modelLookup("rpart")

set.seed(123)

#Using 10-fold cross-validation to train model
train.control = trainControl(method = "cv", number = 10)

#Using rpart method to generate regression tree, using all variables in dataset to predict life expectancy
tree.lifexp.1 = train(life_exp ~ . , data = train.data.q1, method = "rpart", trControl = train.control)

tree.lifexp.1$bestTune
tree.lifexp.1$results
# Note that it only run 3 cp values, so we might want to explore more cp values manually.

#Can use `rpart.plot` function to visualize tree
rpart.plot(tree.lifexp.1$finalModel)
```

##### How to visualize the regression tree?

At the top of the tree, the average life expectancy is 77 (100% data in this node). When we split at *teen_birth*,
* if a place has higher teen_birth rate (>= 33 (yes)), the average life expectancy is 75 (there are 43% of data in this node);
* if a place has lower teen_birth rate (>= 33 (no)), the average life expectancy is 79 (57% of data are in this node).

Following the lower teen birth rate node, it split again at *diabetes*,
* if a county diabetes prevalence is higher than 10% (>= 0.1 (yes)), the average life expectancy is 78 (32% of data in this node);
* if a county diabetes prevalence is lower than 10% (>= 0.1 (no)), the average life expectancy is 80 (25% of data in this node)

### Apply baseline model in test set 

If we are satisfied with this tree, we can go ahead and apply this model to the test set to generate predictions and construct evaluation metrics.
```{r}
#First create predictions
pred.intest.temp = predict(tree.lifexp.1, newdata = test.data.q1)

#Then use postResample to obtain evaluation metrics
## We use postResample for continuous outcome
postResample(pred.intest.temp, test.data.q1$life_exp)
```

Based on the evaluation metrics, we can see that the RMSE is 2.23, and the $R^2$ is only about 0.40. 
Remember, we were using the baseline ("default") cp-values computed by the computer to obtain the results we see above. 
So maybe we would want to tune our hyperparameter (the cp)?

### Tuning hyperparameter (the complexity parameter)

We want to specify `tuneGrid` so `Caret` explores wider variety of cp values.
```{r}
set.seed(123)

#Create different values of cp to try
cp.grid = expand.grid(cp = seq(0.001, 0.1, by = 0.001))

tree.lifexp.2 = train(life_exp ~ ., data = train.data.q1, method = "rpart", trControl = train.control, tuneGrid = cp.grid)
# Notice this time we add a "tuneGrid = " to specify that we want to try our own cp values.

# Check the optimal cp value
tree.lifexp.2$bestTune
tree.lifexp.2$results

#Plot new "best" tree
rpart.plot(tree.lifexp.2$finalModel)
```

Note that we have a new best cp, and the tree plot is much more complicated that the baseline one. 
The tree is too small to look at. We can have other ways to look at variable importance.

### Apply tuned model to test set

```{r}
pred.intest.2 = predict(tree.lifexp.2, newdata = test.data.q1)

#Then use postResample to obtain evaluation metrics
postResample(pred.intest.2, test.data.q1$life_exp)
```

Based on the evaluation metrics, the new model gives us smaller RMSE value (1.86) and a greater $R^2$ (0.59). 

### Explore variable importance in final model 

We will use the `varImp` function to explore variable importance. It will rank each variable in terms of importance and scale them. 
```{r}
varImp(tree.lifexp.2)
```
We can see that `ad_smoking` is the number 1 most important predictor for predicting life expectancy in this dataset, followed by `injury_deaths` and then `teen_birth`. 
Remember in the baseline model, the tree first split at `teen_birth`...

### Unpruned tree 

Using `rpart` without `Caret`, we will get an unpruned tree.
```{r}
# We will use "ANOVA" because this is a regression tree.
tree.lifexp.3 = rpart(life_exp ~ ., data = train.data.q1, method = "anova")

# Check the cp it has been trying (default number of cp is 10)
printcp(tree.lifexp.3)

# Plot to see how the best tuned cp is selected
plotcp(tree.lifexp.3)

# print out the tree but this is hard to visualize
print(tree.lifexp.3)

# Better to visualize the tree using `rpart.plot`
rpart.plot(tree.lifexp.3)
```

*** 

## PART 2: CLASSIFICATION TREES

```{r classtree}
set.seed(123)

#Creating 10-fold cross-validation and using down-sampling because of imbalance in data
train.control.class = trainControl(method = "cv", number = 10, sampling = "down")

#Create sequence of cp parameters to try 
grid.2 = expand.grid(cp = seq(0.001, 0.3, by = 0.01))

#Train model
tree.firearm = train(firearm.class ~ ., data = train.data.q2, method = "rpart", trControl = train.control.class, tuneGrid = grid.2)

# Find best tune cp
tree.firearm
tree.firearm$bestTune
```
Note that the accuracy of cp = 0.011 is 0.766, while the accuracy of cp = 0.041 is 0.761. They have very close accuracy, so maybe we could compare these two trees (using these two cp values) because a larger cp value will give us a simpler tree. **When interpretability is an issue we might want to look at that**.

Visualize the tree.
```{r}
rpart.plot(tree.firearm$finalModel)
```

##### How to visualize the classification tree?

A green node indicates it has the majority of the data; a blue node means it has less proportion of data. In this tree, the root node is a very light blue because the data is split at 50-50. 
The first number indicates the major class (0 or 1).
The second number in the node indicates the proportion of target class in the node. For example, in the root node, it shows 0.50, meaning 50% of the data in the root node is the target class (target class is usually the outcome (1) = higher firearm fatalities). 
The third number shows the percentage of data in the node. The root node has 100% of the data.

The 1st split is at the life expectancy. 
* Counties that have higher life expectancy (>= 77 (yes)), the firearm fatalities ????????? Need clarification

### Run variable importance

```{r}
#Obtain variable importance on the final model within training data
varImp(tree.firearm)

#Note you can get accuracy metric and confusion matrix from training.
confusionMatrix(tree.firearm) # this gives us average accuracy across all 10 folds.
```

### Apply model to test set

If we are satisfied with this model, we can then apply it to our test set.
```{r}
# Option 1
## Create predictions in test set (predict whether a county will have high or low firearm fatalities)
pred.firearm = predict(tree.firearm, test.data.q2)

# Option 2
## Create predictions as probabilities on test set (obtain probabilities when we want to get propensity score or when we are interested in getting a risk score) 
pred.firearm.prob = predict(tree.firearm, test.data.q2, type = "prob")

# Save the evaluation results
eval.results = confusionMatrix(pred.firearm, test.data.q2$firearm.class, positive = "1")
print(eval.results)

#Another potential evaluation: Area under the Receiver Operating Curve (AUROC)
analysis = roc(response = test.data.q2$firearm.class, predictor = pred.firearm.prob[,2])

plot(1-analysis$specificities, analysis$sensitivities, type="l",
  ylab = "Sensitivity", xlab = "1-Specificity", col="black", lwd = 2,
  main = "ROC Curve for Greater Firearm Fatalities")
abline(a = 0, b = 1)
```

